{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 18:48:17.963731: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-06 18:48:18.187353: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-06 18:48:18.187419: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-06 18:48:18.188581: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-06 18:48:18.295137: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-06 18:48:18.297024: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 18:48:20.744508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from trdg.generators import GeneratorFromStrings\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholding(img):\n",
    "    \"\"\"\n",
    "    Applies thresholding to the input image\n",
    "    \"\"\"\n",
    "    img.save(\"temp.jpg\")\n",
    "    img = cv2.imread(\"temp.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    _, im_gray_th_otsu = cv2.threshold(img, 128, 192, cv2.THRESH_OTSU)\n",
    "\n",
    "    _, im_gray_th = cv2.threshold(im_gray_th_otsu, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    im_gray_th = cv2.bitwise_not(im_gray_th)\n",
    "\n",
    "    return Image.fromarray(im_gray_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 33)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABcAAAAhCAIAAAC9a6dHAAABgElEQVR4nO2TMauCUBTHj/ZIHFzabAgEIRoKtwRb/AB+ioY+hk5t0eDg6GAfIGoSod29rcEmXSKhqMGK2yDIfXbffZUPHjzef/Ke/+F3zj33CPBTQl/LNE1BEDiOq0TJ5XmeKIqiKDYajfcphdbrdavVqkpBCCVJ0uv1qlIQQqfTSdd1nMDkFDwUBMFutyuOiqJ0Op1S4SzLyiMvlep2u7g7GAxs216tVnjO8XgcjUY0iqZpj7eWJGk2m5UyC5clzImkKIpc18Ujl8vFtu3XegGAZrNpWRaxnWd7AYA4jheLBdF6gQIPr/kOpd/vz+fz4ng+n9vt9qcK387FMIw0TUuPXbgflOLT6XQ4HObf9Xq9tGa32+0pCs/zgiAQre12K8tycaTNhWUJLkIoDENJkvBeaJQ4jvf7PR65Xq/L5VJVVUI2Zbrj8TgPHg6HMAwdxyHWo80FADabje/7ABAEwWQyoaU++QdQ9Nru/lP+FIVhmHdI+Mqpqlqr1ar29pu6A8vY20TVfa9qAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=23x33>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a generator object \n",
    "generator = GeneratorFromStrings(\n",
    "    ['B', 'D', 'F', 'G', 'H', 'J', 'K', 'L', 'N', 'P', 'R', 'S', 'T', 'V', 'W', 'X', 'Z', '1', '2','3','4','5','6','7','8','9','0'],\n",
    "    count=10000,\n",
    "    fonts=['../lp_template_files/font_dutch_lp.ttf'],\n",
    "    skewing_angle=7,\n",
    "    random_skew=True,\n",
    "    fit=True,\n",
    "    margins=(0,0,0,0),\n",
    "    distorsion_type=1,\n",
    "    background_type=1,\n",
    "    text_color='#000000',\n",
    "    size=40,\n",
    ")\n",
    "\n",
    "img_count = 0\n",
    "\n",
    "for img, lbl in generator:\n",
    "    # apply thresholding\n",
    "    img = thresholding(img)\n",
    "\n",
    "    # find the bounding box of the image\n",
    "    cnts, _ = cv2.findContours(np.array(img), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boundingBox = [cv2.boundingRect(c) for c in cnts][0]\n",
    "\n",
    "    # crop the image to the bounding box\n",
    "    img = img.crop((boundingBox[0], boundingBox[1], boundingBox[0]+boundingBox[2], boundingBox[1]+boundingBox[3]))\n",
    "\n",
    "    # resize the image to 20x30\n",
    "    img = img.resize((20, 30))\n",
    "\n",
    "    # create blank black image\n",
    "    new_img = Image.new(\"RGB\", (23, 33), \"black\")\n",
    "\n",
    "    # paste the original image on the blank image in middle\n",
    "    width, height = img.size\n",
    "    x = 23//2 - width//2\n",
    "    y = 33//2 - height//2\n",
    "    new_img.paste(img, (x, y))\n",
    "\n",
    "    # save the image\n",
    "    new_img.save(f'../../images/train_ocr/{lbl}-{img_count}.png')\n",
    "    img_count += 1\n",
    "\n",
    "\n",
    "print(new_img.size)\n",
    "new_img  \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
