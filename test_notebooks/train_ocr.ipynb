{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 12:04:29.936141: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-06 12:04:30.156796: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-06 12:04:30.156864: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-06 12:04:30.158071: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-06 12:04:30.258221: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-06 12:04:30.261359: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 12:04:32.387163: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import cv2\n",
    "np.random.seed(42)                      \n",
    "from keras.models import Sequential             \n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '../../images/train_ocr/'\n",
    "images = os.listdir(PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd70ada4950>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load images and labels into numpy arrays\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for image in images:\n",
    "    img = Image.open(PATH_TO_DATA + image)\n",
    "    # convert to black and white\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img) / 255\n",
    "    # array to int\n",
    "    img = img.astype(int)\n",
    "    X.append(img)\n",
    "    y.append(image[0])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X.shape, y.shape\n",
    "plt.imshow(X[30], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1002, 33, 23), (1002, 1))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert arrays to vectors\n",
    "# X = X.reshape(X.shape[0], -1)\n",
    "y = y.reshape(y.shape[0], -1)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1002, 27)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_binarizer.pkl']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(lb, 'label_binarizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 33)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = y.shape[1]\n",
    "num_pixels = X.shape[1]\n",
    "\n",
    "num_classes, num_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 31, 21, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 15, 10, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 13, 8, 64)         18496     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 6656)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 27)                179739    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 198555 (775.61 KB)\n",
      "Trainable params: 198555 (775.61 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    # Convolutional layer with rectified linear unit activation\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(33, 23, 1)))\n",
    "    # Max pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "    # Softmax layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "opt = SGD(lr = 0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer= opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 0.2211 - accuracy: 0.9481\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.1613 - accuracy: 0.9601\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.3709 - accuracy: 0.9421\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.1109 - accuracy: 0.9731\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 0.0528 - accuracy: 0.9940\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0429 - accuracy: 0.9950\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.0573 - accuracy: 0.9880\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 1s 29ms/step - loss: 0.0175 - accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fd70acb9350>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J']\n"
     ]
    }
   ],
   "source": [
    "# model.save('ocr_model.h5')\n",
    "\n",
    "predictions = [0.00092543,  8.6983e-09,  0.00029555,    0.018453,  7.9169e-06,  6.3804e-05,  3.1863e-07,  1.2928e-06,  2.9356e-06,  1.5965e-05,  0.00024953,   0.0010558,  1.5302e-10,  4.9721e-07,  1.2044e-05,     0.97877,   1.354e-09,  2.9288e-08,  0.00011888,  3.7258e-08,   1.523e-07,  7.3191e-07,    1.93e-08,   1.979e-05,  1.2073e-06,  4.7237e-07,\n",
    "    6.455e-06]\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# transform the preidctions using the label binarizer\n",
    "preds = lb.inverse_transform(predictions.reshape(1, -1))\n",
    "\n",
    "print(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
