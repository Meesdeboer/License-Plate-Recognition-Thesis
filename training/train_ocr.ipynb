{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 18:50:01.698998: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-06 18:50:01.772111: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-06 18:50:01.772185: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-06 18:50:01.772219: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-06 18:50:01.784517: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-06 18:50:01.786478: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 18:50:03.482367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import cv2\n",
    "np.random.seed(42)                      \n",
    "from keras.models import Sequential             \n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '../../images/train_ocr/'\n",
    "images = os.listdir(PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2a20db8150>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load images and labels into numpy arrays\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for image in images:\n",
    "    img = Image.open(PATH_TO_DATA + image)\n",
    "    # convert to black and white\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img) / 255\n",
    "    # array to int\n",
    "    img = img.astype(int)\n",
    "    X.append(img)\n",
    "    y.append(image[0])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X.shape, y.shape\n",
    "plt.imshow(X[30], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 33, 23), (10000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert arrays to vectors\n",
    "# X = X.reshape(X.shape[0], -1)\n",
    "y = y.reshape(y.shape[0], -1)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the label encoder lb\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(lb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 33)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = y.shape[1]\n",
    "num_pixels = X.shape[1]\n",
    "\n",
    "num_classes, num_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 22, 32)        160       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 22, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 31, 20, 32)        6176      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 15, 10, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 15, 10, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4800)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 27)                129627    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 135963 (531.11 KB)\n",
      "Trainable params: 135963 (531.11 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(33, 23, 1)))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(2, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # model.add(Conv2D(32, kernel_size=(2, 3), activation='relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "\n",
    "    # Softmax layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr = 0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer= opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 18:50:45.256794: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 60720000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 15s 43ms/step - loss: 0.1416 - accuracy: 0.9707\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 1.5466e-04 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 4.9321e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 13s 40ms/step - loss: 2.2459e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 8.3831e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 4.2637e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 2.7388e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 1.7256e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 1.2586e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 8.2681e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f2a2c0b5050>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mees/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('ocr_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
