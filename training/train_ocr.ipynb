{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 16:09:45.810882: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-02 16:09:45.863332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-02 16:09:45.863388: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-02 16:09:45.863419: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-02 16:09:45.871475: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-02 16:09:45.871922: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-02 16:09:47.061580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import cv2\n",
    "np.random.seed(42)                      \n",
    "from keras.models import Sequential             \n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '../../images/train_ocr_test/'\n",
    "images = os.listdir(PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f659edc1290>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load images and labels into numpy arrays\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for image in images:\n",
    "    img = Image.open(PATH_TO_DATA + image)\n",
    "    # convert to black and white\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img) / 255\n",
    "    # array to int\n",
    "    img = img.astype(int)\n",
    "    X.append(img)\n",
    "    y.append(image[0])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X.shape, y.shape\n",
    "plt.imshow(X[30], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 33, 23), (20000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert arrays to vectors\n",
    "# X = X.reshape(X.shape[0], -1)\n",
    "y = y.reshape(y.shape[0], -1)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the label encoder lb\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(lb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 33)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = y.shape[1]\n",
    "num_pixels = X.shape[1]\n",
    "\n",
    "num_classes, num_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 22, 32)        160       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 22, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 31, 20, 32)        6176      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 15, 10, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 15, 10, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4800)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 27)                129627    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 135963 (531.11 KB)\n",
      "Trainable params: 135963 (531.11 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(33, 23, 1)))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(2, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # model.add(Conv2D(32, kernel_size=(2, 3), activation='relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "\n",
    "    # Softmax layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr = 0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer= opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 22s 33ms/step - loss: 0.0908 - accuracy: 0.9782\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 21s 34ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 8.7665e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 20s 33ms/step - loss: 4.7669e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 1.0347e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 21s 34ms/step - loss: 5.9716e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 4.6123e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 2.5094e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 2.2568e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 21s 34ms/step - loss: 0.0067 - accuracy: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f65a938a990>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mees/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('ocr_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
